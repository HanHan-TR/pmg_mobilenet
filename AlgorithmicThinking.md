
# 基于深度特征与帧间差异分析的可视喉罩移位脱出监测算法 思路梳理

@By： 王晗 2025.08.26

基于微型摄像头采集的喉罩置管临床视频数据开发该移位脱出监测算法。微型摄像头集成在喉罩管体上，可以采集到喉罩置入过程中患者的气道图像。
通过分析喉罩置入到合适位置后以及喉罩移位状态下视频图像的特征差异来分析判断喉罩是否发生移位脱出，当判定为移位脱出时发出警报。

由于临床实际中，喉罩移位的概率较低，因此几乎采集不到喉罩移位脱出的真实视频数据。
因此，考虑使用喉罩置入过程中的视频数据，并将其倒序播放，模拟喉罩移位脱出的过程；

此外，受患者生理结构的个体差异、喉罩型号选择是否合适、医生的置管操作手法的个体差异，喉罩制作工艺的误差等多种因素的影响，在采集到的临床数据中，
对于不同的患者，喉罩置入到合适的位置后，视频图像中看到的生理结构以及生理结构的角度、位置各不相同，无法根据统一的标准去判断喉罩是否到位。也就意味着，使用一定标准将喉罩图像数据分类成移位图像与未移位图像，然后训练图像分类网络，通过分类方法判断移位脱出是不可行的。

因此，计划基于帧间差异法开发本算法。基本思路如下：

1. 首先，喉罩置入到合适的位置后，由医生通过软件的UI交互界面选取一帧图像作为标准图像；
2. 由算法判断当前帧图像与标准图像之间的差异，当差异大于某一设定阈值时，即判定为喉罩移位脱出；

需要说明的是，由于患者的呼吸导致的气道规律性运动，即使在没有移位的状态下，喉罩图像的内容也存在小幅度的变化。因此，计划使用深度卷积神经网络对图像提取深度特征，
然后使用图像帧之间深度特征的差异性来表示图像之间的差异性。由于深度特征能够更好地对图像中的语义信息进行建模，且对图像的微小变化具有鲁棒性，因此这样做可以避免因患者呼吸引起的图像差异超过阈值而导致的算法误报问题；

对于上述卷积神经网络的训练，可以采取以下思路：

将采集到的喉罩置管过程的视频数据按照图像中的内容划分并制作分类数据集，例如，将临床图像分为：体外、口腔、会厌、声门、分泌物等几个类别，在该分类数据集上训练图像分类网络。这样，该网络就具备了有关喉罩临床数据的先验知识。例如，使用MobileNetV2模型训练分类网络，然后将训练好的网络作为特征提取网络，将其avgpool7×7层输出的1280×1×1维特征作为每个图像的深度特征表示；

对于差异阈值的设定和选择方法，大体思路如下：

1. 考虑到个体性差异，阈值应该针对每个患者由算法自适应设定；
2. 自适应设定阈值的基本思路为：
  - 记医生开始进行喉罩置管的时刻为$t1$,置管结束后医生手动设定标准图像的时刻为$t2$，首先算法获取到$t1$~$t2$这段时间的视频图像，将这段时间的视频图像记为集合$A$。由于A中的图像包含了置管过程中的图像，也就是
    喉罩未置入到位的图像，因此可以用来模拟喉罩移位脱出时的情形；
  - 假设将医生设定的标准图像记为$im$，计算$im$的深度特征与集合A中图像的深度特征的差异，取差异的平均值作为上述差异性判断的阈值，将该阈值记为$d_s$；
  - 此外，还可以根据采集到的临床数据，统计在喉罩未发生移位脱出的状态下，因呼吸导致的深度特征差异的平均值，记为$d_n$，设定$d_s$不能小于$d_n$，这样就引入了临床数据的统计信息，能够帮助在兼顾个体性差异的同时，设定更加科学的阈值;

对于$t1$~$t2$这段时间的视频的获取方法，有以下思路：

方案一：可以让医生手动设定开始置管的时间（在UI界面上添加开始置管的按钮，医生按下该按钮的时刻即为$t1$），医生设置标准图像的时刻即为$t2$，软件从$t1$时刻开始，以较低的频率（例如3fps）收集图像帧，直至$t2$时刻，收集到的图像帧即为集合$A$；

方案二：由于开始置管时，医生要将喉罩拿到患者口腔附近，图像中可以看到患者的口腔、牙齿等结构，因此可以使用分类网络进行判断（该分类网络可以使用上述的图像特征提取网络），当监测到患者口腔时，记为$t1$时刻，医生设置标准图像的时刻即为$t2$，软件从$t1$时刻开始，以较低的频率（例如3fps）收集图像帧，直至$t2$时刻，收集到的图像帧即为集合$A$；

对于上述两种方案，都需要考虑以下问题：

1. $t1$~$t2$时间的长短决定了集合$A$中图像的数量，当时间过长时，集合$A$中图像的数量过多，这样会占用较多的设备内存，也会增加阈值计算时的计算量；
2. 在$t1$~$t2$的时间段内，医生在置管过程中，可能会因为置管过程受阻而在某一位置停留较长时间，导致集合$A$中具有某有相似内容的图像较多，从而影响阈值$d_s$的计算；
3. 医生在完成置管后，可能因为需要处理其他事情而延迟对于标准图像的设定，导致集合$A$中出现了大量置管结束后的图像，这些图像与标准图像的差异较小，使得$d_s$的计算结果较小，算法过于灵敏，出现误报；

对于以上问题，解决思路如下：

使用关键帧提取与视频摘要技术提取原始集合$A$中的关键帧，将关键帧形成的集合记为$A_{sub}$, 并设定$A_{sub}$集合的容量，例如30帧。将上述阈值的计算方法改为：计算$im$的深度特征与集合$A_{sub}$中图像的深度特征的差异，取差异的平均值作为上述差异性判断的阈值，将该阈值记为$d_s$，同时设定$d_s$不能小于$d_n$。